training_tweets_csv_path: training_tweets.csv
test_tweets_csv_path: test_tweets.csv

model_path:                 # Leave empty if you want to use the default path of the process

device: cuda

model_parameters:
  bert_model_name: dbmdz/bert-base-turkish-128k-cased
  layers: [
    {"name": "linear", "in": 768, "out": 192},
    {"name": relu},
    {"name": "linear", "in": 192, "out": 48},
    {"name": relu},
    {"name": "linear", "in": 48, "out": 12},
    {"name": relu},
    {"name": "sigmoid", "in": 32, "out": 3}, #there is 32 unique label for multi-text classfication so we should use sigmoid for one-hot vektor
  ]

training_parameters:
  validation_size: 0.2      # A percentage between 0 and 1
  batch_size: 1
  learning_rate: 0.00001
  class_weights: True       # True or False
  optimizer: ADAM           # SGD or ADAM
  scheduler:                # Leave empty to disable
  num_epochs: 5